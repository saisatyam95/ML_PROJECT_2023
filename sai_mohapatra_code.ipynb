{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2afd11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from array import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Random Forest\n",
    "# Logistic Regression\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "# Gaussian Naive Bayes\n",
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data-points into 85% for training and 15% for testing, selected randomly using ***sklearn.model_selection.test_train_split()*** with stratification.\n",
    "\n",
    "Then we create 25 seperate dataframes, each with 18 unique features.\n",
    "This is done to make a seperate data-frame object for each of the 25 groups present in the original data, as required for the training of the Multi-Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5766aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data = pd.read_csv(\"C:/Users/ssmsa/Documents/CODE/ml/project_p2/training_data.csv\")\n",
    "data1 = pd.read_csv(\"C:/Users/ssmsa/Documents/CODE/ml/project_p2/training_data_targets.csv\", names = ['target'])\n",
    "\n",
    "X = data\n",
    "y = data1['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, stratify = y)\n",
    "\n",
    "# X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "X_train_split = [0]*25\n",
    "\n",
    "i = 0\n",
    "a = 0\n",
    "b = 17\n",
    "while i < 25 :\n",
    "    X_train_split[i]  = X_train.iloc[:,a:b+1]\n",
    "    a = a + 18\n",
    "    b = b + 18\n",
    "    i = i + 1\n",
    "    \n",
    "X_test_split = [0]*25\n",
    "\n",
    "i = 0\n",
    "a = 0\n",
    "b = 17\n",
    "while i < 25 :\n",
    "    X_test_split[i]  = X_test.iloc[:,a:b+1]\n",
    "    a = a + 18\n",
    "    b = b + 18\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the classifiers with hyperparameter tuning enabled, using ***sklearn.model_selection.GridSearchCV()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3f963cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random forest\n",
    "search_space = {'n_estimators' : [int(x) for x in np.linspace(start = 20, stop = 50, num = 10)],\n",
    "                'max_features' : ['log2' , 'sqrt'],\n",
    "               'max_depth' : [4, 5]}\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight='balanced')\n",
    "rf_tuned = GridSearchCV(estimator = rf_model, param_grid = search_space, scoring = 'f1_macro', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e273869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "search_space = {'solver' : ['liblinear', 'sag', 'saga'],\n",
    "               'max_iter' : [200,  10000]}\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_tuned = GridSearchCV(estimator = lr_model, param_grid = search_space, scoring = 'f1_macro', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86f92107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear discriminant analysis (lda)\n",
    "search_space = {'solver' : ['lsqr', 'eigen'],\n",
    "               'shrinkage' : ['auto', 0.5]}\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_tuned = GridSearchCV(estimator = lda_model, param_grid = search_space, scoring = 'f1_macro', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c5c5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5,  n_repeats=3)\n",
    "search_space = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_tuned = GridSearchCV(estimator = gnb_model, param_grid = search_space, scoring = 'f1_macro', cv = cv_method, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6888d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "cv_method1 = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3, random_state = 0)\n",
    "search_space = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "               'gamma' : ['scale', 'auto']}\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_tuned = GridSearchCV(estimator = svm_model, param_grid = search_space, cv = cv_method1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a567b7",
   "metadata": {},
   "source": [
    "#### Fitting Data and Evaluating Performance with Confusion Matrix for ***precision, recall and f1-score***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Hyperparameter tuning using GridSearchCV has been used for all the classifiers below for best performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91f5c8",
   "metadata": {},
   "source": [
    "Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca1f955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[11  1]\n",
      " [ 1 11]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.92      0.92      0.92        12\n",
      "           P       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.92      0.92      0.92        24\n",
      "weighted avg       0.92      0.92      0.92        24\n",
      "\n",
      "Parameters :  {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 33}\n"
     ]
    }
   ],
   "source": [
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    " #print(\"The best selected best parameters are :\", rf_tuned.best_params_, \"\\n\\n\")\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Parameters : \", rf_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99f326",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb76dc6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[11  1]\n",
      " [ 2 10]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.85      0.92      0.88        12\n",
      "           P       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.88      0.88      0.87        24\n",
      "weighted avg       0.88      0.88      0.87        24\n",
      "\n",
      "Parameters :  {'max_iter': 10000, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "lr_tuned.fit(X_train, y_train)\n",
    "y_pred = lr_tuned.predict(X_test)\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Parameters : \", lr_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ed36c",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73ec7ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[12  0]\n",
      " [ 3  9]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.80      1.00      0.89        12\n",
      "           P       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.90      0.88      0.87        24\n",
      "weighted avg       0.90      0.88      0.87        24\n",
      "\n",
      "Parameters :  {'shrinkage': 'auto', 'solver': 'eigen'}\n"
     ]
    }
   ],
   "source": [
    "lda_tuned.fit(X_train, y_train)\n",
    "y_pred = lda_tuned.predict(X_test)\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Parameters : \", lda_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ead37",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d578959d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[10  2]\n",
      " [ 1 11]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.91      0.83      0.87        12\n",
      "           P       0.85      0.92      0.88        12\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.88      0.88      0.87        24\n",
      "weighted avg       0.88      0.88      0.87        24\n",
      "\n",
      "Parameters :  {'var_smoothing': 6.579332246575682e-08}\n"
     ]
    }
   ],
   "source": [
    "gnb_tuned.fit(X_train, y_train)\n",
    "y_pred = gnb_tuned.predict(X_test)\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Parameters : \", gnb_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cf92a",
   "metadata": {},
   "source": [
    "Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca6081e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[11  1]\n",
      " [ 2 10]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.85      0.92      0.88        12\n",
      "           P       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.88      0.88      0.87        24\n",
      "weighted avg       0.88      0.88      0.87        24\n",
      "\n",
      "Parameters :  {'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "svm_tuned.fit(X_train, y_train)\n",
    "y_pred = svm_tuned.predict(X_test)\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print(\"Parameters : \", svm_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Classifiers**\n",
    "\n",
    "**For Multi-Classifier approach, the classifier is trained on each feature group seperately and to predict the the labels. Subsequently 25 different predictions are obtained for the class label of each datapoint. The final label is then decided by majority vote.**\n",
    "\n",
    "**The Confusion Matrix, prescision, recall and f1-score are shown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096c47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_pred = [0]*25\n",
    "ym_pred_final = [0]*24\n",
    "ym_score = [0]*25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2c00e",
   "metadata": {},
   "source": [
    "**Random Forest Multi-Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53c8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[12  0]\n",
      " [ 1 11]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.92      1.00      0.96        12\n",
      "           P       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.96      0.96      0.96        24\n",
      "weighted avg       0.96      0.96      0.96        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    rf_tuned.fit(X_train_split[i], y_train)\n",
    "    ym_pred[i] = rf_tuned.predict(X_test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 24:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (ym_pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (ym_pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        ym_pred_final[i] = 'H'\n",
    "    else :\n",
    "        ym_pred_final[i] = 'P'\n",
    "    i = i+1\n",
    "\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, ym_pred_final))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, ym_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6243478260869566, 0.916083916083916, 0.5714285714285714, 0.7482517482517481, 0.7913043478260869, 0.7078260869565216, 0.8321678321678322, 0.6666666666666666, 0.7037037037037037, 0.5208711433756806, 0.6571428571428571, 0.6643356643356644, 0.6643356643356644, 0.6243478260869566, 0.8321678321678322, 0.6643356643356644, 0.8333333333333334, 0.7913043478260869, 0.7428571428571429, 0.6666666666666666, 0.5555555555555556, 0.6571428571428571, 0.7913043478260869, 0.7913043478260869, 0.6643356643356644]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    ym_score[i]  = f1_score(y_test, ym_pred[i], average='macro')\n",
    "    i = i + 1\n",
    "    \n",
    "print(ym_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba6f80",
   "metadata": {},
   "source": [
    "**Logistic Regression Multi-Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db6f6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssmsa\\.conda\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[11  1]\n",
      " [ 0 12]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       1.00      0.92      0.96        12\n",
      "           P       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.96      0.96      0.96        24\n",
      "weighted avg       0.96      0.96      0.96        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    lr_tuned.fit(X_train_split[i], y_train)\n",
    "    ym_pred[i] = lr_tuned.predict(X_test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 24:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (ym_pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (ym_pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        ym_pred_final[i] = 'H'\n",
    "    else :\n",
    "        ym_pred_final[i] = 'P'\n",
    "    i = i+1\n",
    "\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, ym_pred_final))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, ym_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1ee85",
   "metadata": {},
   "source": [
    "**Linear Discriminant Alalysis Multi-Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01cb4232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[11  1]\n",
      " [ 3  9]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.79      0.92      0.85        12\n",
      "           P       0.90      0.75      0.82        12\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.84      0.83      0.83        24\n",
      "weighted avg       0.84      0.83      0.83        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    lda_tuned.fit(X_train_split[i], y_train)\n",
    "    ym_pred[i] = lda_tuned.predict(X_test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 24:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (ym_pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (ym_pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        ym_pred_final[i] = 'H'\n",
    "    else :\n",
    "        ym_pred_final[i] = 'P'\n",
    "    i = i+1\n",
    "\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, ym_pred_final))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, ym_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316cbcf",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes Multi-Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca48be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[12  0]\n",
      " [ 3  9]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.80      1.00      0.89        12\n",
      "           P       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.90      0.88      0.87        24\n",
      "weighted avg       0.90      0.88      0.87        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    gnb_tuned.fit(X_train_split[i], y_train)\n",
    "    ym_pred[i] = gnb_tuned.predict(X_test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 24:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (ym_pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (ym_pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        ym_pred_final[i] = 'H'\n",
    "    else :\n",
    "        ym_pred_final[i] = 'P'\n",
    "    i = i+1\n",
    "\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, ym_pred_final))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, ym_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2fcb9",
   "metadata": {},
   "source": [
    "**Support Vector Machine Multi-Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91227f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "\n",
      "[[12  0]\n",
      " [ 2 10]]\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.86      1.00      0.92        12\n",
      "           P       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.93      0.92      0.92        24\n",
      "weighted avg       0.93      0.92      0.92        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    svm_model.fit(X_train_split[i], y_train)\n",
    "    ym_pred[i] = svm_model.predict(X_test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 24:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (ym_pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (ym_pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        ym_pred_final[i] = 'H'\n",
    "    else :\n",
    "        ym_pred_final[i] = 'P'\n",
    "    i = i+1\n",
    "\n",
    "print(\"Confusion Matrix : \\n\")\n",
    "print(confusion_matrix(y_test, ym_pred_final))\n",
    "print(\"\\nClassification Report : \\n\")\n",
    "print(classification_report(y_test, ym_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above results, we can see that the Random Forest Multi-Classifier and the Linear Regression Multi-Classifier have the best results in terms of f1-score (0.96)**\n",
    "\n",
    "**I have selected Linear Regression as it has higher Recall (1.0) compared to Linear Regression (0.96) for patients(P) as it is not as big a problem if a healthy person is predicted patient as compared to when a patient is predicted healthy**\n",
    "\n",
    "**Now, training the model on the entire training data and outputing the results into a text file -** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data\n",
    "\n",
    "train_split = [0]*25\n",
    "\n",
    "i = 0\n",
    "a = 0\n",
    "b = 17\n",
    "while i < 25 :\n",
    "    train_split[i]  = train.iloc[:,a:b+1]\n",
    "    a = a + 18\n",
    "    b = b + 18\n",
    "    i = i + 1\n",
    "\n",
    "test = pd.read_csv(\"C:/Users/ssmsa/Documents/CODE/ml/project_p2/test_data.csv\")\n",
    "\n",
    "test_split = [0]*25\n",
    "\n",
    "i = 0\n",
    "a = 0\n",
    "b = 17\n",
    "while i < 25 :\n",
    "    test_split[i]  = test.iloc[:,a:b+1]\n",
    "    a = a + 18\n",
    "    b = b + 18\n",
    "    i = i + 1\n",
    "\n",
    "pred = [0]*25\n",
    "pred_final = [0]*18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 25 :\n",
    "    lr_tuned.fit(train_split[i], y)\n",
    "    pred[i] = lr_tuned.predict(test_split[i])\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "h = 0\n",
    "p = 0\n",
    "while i < 18:\n",
    "    j = 0\n",
    "    h = 0\n",
    "    p = 0\n",
    "    while j < 25:\n",
    "        if (pred[j][i]) == 'H':\n",
    "            h = h + 1\n",
    "        if (pred[j][i]) == 'P' :\n",
    "            p = p + 1\n",
    "        j=j+1\n",
    "    if h > p :\n",
    "        pred_final[i] = 'H'\n",
    "    else :\n",
    "        pred_final[i] = 'P'\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred_final, columns = ['A']) \n",
    "np.savetxt('21233.txt', df['A'], fmt='%c', delimiter='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
